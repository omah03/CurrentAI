{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKoZXxc3JJbm"
   },
   "source": [
    "# Welcome to assignment #5!\n",
    "\n",
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry. We need you to upload the .ipynb-file and the exported .pdf of this notebook.\n",
    "\n",
    "If you have any questions, ask them in either in the tutorials or in the \"Mattermost\" channel. The channel is called SSL_WS_2324, you can join the server using this [Link](https://mattermost.imp.fu-berlin.de/signup_user_complete/?id=h5ssupqokprtpyf4dr7xabiwpc&md=link&sbr=su) and can search for the public channel.\n",
    "\n",
    "\n",
    "This week we will learn representations using a Contrastive loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0s2jT1GuJJbo"
   },
   "source": [
    "# Slide Review\n",
    "\n",
    "[Google Form](https://forms.gle/3DTirLWzpmbatqnV7) for the slide review. Please take a minute to scroll over the slides again and improve your lecture.\n",
    "\n",
    "Please make sure to only choose your top 5 slides per lecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5vvcClwJJbp"
   },
   "source": [
    "# PapagAI\n",
    "\n",
    "From the second week onwards we started the reflective study.\n",
    "Register on the [PapagAI website](https://www.papag.ai) and write your first reflection about your impressions and challenges in the context of the lectures and tutorials you had this and previous week. The size of reflection can be anywhere bigger than 100 words. You can check out this [YouTube video](https://www.youtube.com/watch?v=QdmZHocZQBk&ab_channel=FernandoRamosL%C3%B3pez) with instructions on how to register, create a reflection and get an ai feedback.\n",
    "\n",
    "Please note, that this task is an obligatory one for this course and make sure each of you does the reflection, not only one person per group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDkzt6BkJJbq"
   },
   "source": [
    "#### Please state both names of your group members here:\n",
    "Authors: Omar Ahmed and Can Aydin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4Xc0-YBJJbq"
   },
   "source": [
    "# Assignment 5: Contrastive Learning\n",
    "\n",
    "## Ex. 5.1 Supervised model baseline\n",
    "\n",
    "Implement a small supervised ConvNet and train it on [MNIST](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) to have a baseline accuracy to compare against later. This helps to evaluate the representation quality later. Try using similar hyperparameters (i.e., Learning rate) for your contrastive learning in 5.2 and 5.3. You may train for 3-5 epochs. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaZTyv2CJJbr",
    "outputId": "4aa46c3b-bc58-4761-fae4-751b04ea072c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b4074b810d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split,Dataset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0ALlrx3DPzyP"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(mnist_dataset))\n",
    "test_size = len(mnist_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(mnist_dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6FDazAuUQUx"
   },
   "source": [
    "#### The Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fnuF_VxaRhcj"
   },
   "outputs": [],
   "source": [
    "class ConvNeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ConvNeuralNetwork, self).__init__()\n",
    "    self.conv_layers = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    )\n",
    "    self.linear_layers = nn.Sequential(\n",
    "    nn.Linear(32 * 7 * 7, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32,10)\n",
    "  )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv_layers(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.linear_layers(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0y1dVtSnRRNJ"
   },
   "outputs": [],
   "source": [
    "model = ConvNeuralNetwork()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojDvU6SXWZS7",
    "outputId": "d9f5a9c3-060f-49bd-b18d-8806eea03e46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Accuracy: 73.95%\n",
      "Epoch 1, Train Accuracy: 95.04%\n",
      "Epoch 2, Train Accuracy: 96.64%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = []\n",
    "epoch_count = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        y_train = model(inputs)\n",
    "        loss = loss_function(y_train, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_train_softmax = F.softmax(y_train,dim=1)\n",
    "        _, predicted = torch.max(y_train_softmax,1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_accuracy_r = correct / total\n",
    "    train_accuracy.append(train_accuracy_r)\n",
    "    epoch_count.append(epoch+1)\n",
    "    print(f\"Epoch {epoch}, Train Accuracy: {100 * train_accuracy_r:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qKy0fYNJJbs"
   },
   "source": [
    "## Ex. 5.2 Contrastive Learning\n",
    "\n",
    "Implement a ConvNet to learn representations in a constrastive fashion for the [MNIST](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) dataset. 3 Conv layers should be sufficient. You don't need a fully connected layer in the end during training. **(RESULT)**\n",
    "\n",
    "Test the quality of your representations using a classifier consisting of just one linear layer. What accuracy can you achieve based on your representations? Compare against the accuracy of your supervised model. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6eca7YXK6nTx"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees = 20, translate = (0.1,0.1), scale = (0.9,1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform = transform)\n",
    "augmented_dataset = datasets.MNIST(root='./data', train = False, download= True, transform = augmentation)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "loader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=False)\n",
    "augmented_loader = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Z5EAl3FFZjcv"
   },
   "outputs": [],
   "source": [
    "class ContrastiveConvNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(ContrastiveConvNet, self).__init__()\n",
    "    self.conv_layers = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv_layers(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9raz3xHiwXdy"
   },
   "outputs": [],
   "source": [
    "def simple_contrastive_loss(z_i,z_j,q):\n",
    "  distance = F.pairwise_distance(z_i,z_j,p=2)\n",
    "  loss = q * distance - (1-q) * distance\n",
    "  return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Lxhe77bKdvei"
   },
   "outputs": [],
   "source": [
    "model_1 = ContrastiveConvNet()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unqVkKMkvhYE",
    "outputId": "d6635917-7f2d-475f-8171-ef3a832a05b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -15180371.17985091\n",
      "Epoch 2, Loss: -290139717.07348245\n",
      "Epoch 3, Loss: -1291932111.9488819\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  total_loss = 0\n",
    "  for (data,_), (aug_data,_) in zip(loader,augmented_loader):\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    z_i = model_1(data)\n",
    "    z_j = model_1(aug_data)\n",
    "\n",
    "    positive_loss = simple_contrastive_loss(z_i,z_j,torch.ones(data.size(0)))\n",
    "    loss += positive_loss\n",
    "\n",
    "    for anchor_index in range(data.size(0)):\n",
    "      for negative_index in range(data.size(0)):\n",
    "        if anchor_index != negative_index:\n",
    "          negative_loss = simple_contrastive_loss(z_i[anchor_index].unsqueeze(0), z_i[negative_index].unsqueeze(0),torch.zeros(1))\n",
    "          loss += negative_loss\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "  average_loss = total_loss/len(loader)\n",
    "  print(f\"Epoch {epoch+1}, Loss: {average_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GU1VHUmEAgzE"
   },
   "outputs": [],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "  def __init__(self,i,n):\n",
    "    super(LinearClassifier,self).__init__()\n",
    "    self.fc = (nn.Linear(i,n))\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RhXj8_MdBphp"
   },
   "outputs": [],
   "source": [
    "classifier = LinearClassifier(1568 ,10)\n",
    "classifier_optim = torch.optim.Adam(classifier.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtUIsm43B3lK",
    "outputId": "09741283-c2dd-42c5-bdb5-710d638443c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveConvNet(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EUHeSUJPMwG2"
   },
   "outputs": [],
   "source": [
    "for param in model_1.conv_layers.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HK2NBuqN4-w",
    "outputId": "998a212e-917e-4d6a-d16e-db3423942a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1568])\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "sample_data, _ = next(iter(loader))\n",
    "sample_output = model_1(sample_data)\n",
    "print(sample_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYWnWYxOND8a",
    "outputId": "de0f65ae-d137-456a-c175-2394657ee761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 9.87%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "  for (data,target) in loader:\n",
    "    representations = model_1(data)\n",
    "    outputs = classifier(representations)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "\n",
    "    total+= target.size(0)\n",
    "    correct += (predicted == target).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cu0YdB4COC-V"
   },
   "source": [
    "Horrible accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2YmDf20JJbt"
   },
   "source": [
    "## Ex. 5.3 Contrastive Loss with Margin (BONUS)\n",
    "\n",
    "Implement a contrastive loss function with margin. Does this improve your representation quality? Check the accuracy with a classifier like in 5.2. Compare your results with those from 5.1 and 5.2. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "SABG6HoeJJbu"
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(z_ref, z_pos,z_neg,margin = 1.0):\n",
    "  positive_distance = F.pairwise_distance(z_ref, z_pos, p = 2)\n",
    "  negative_distance = F.pairwise_distance(z_ref, z_neg, p = 2)\n",
    "  loss = torch.clamp(positive_distance - negative_distance + margin, min = 0.0)\n",
    "  return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ROXUIYQ3ORcW"
   },
   "outputs": [],
   "source": [
    "model_2 = ContrastiveConvNet()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZa_VF32L6tc",
    "outputId": "06d53f86-9c08-457f-89a4-215d60301bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 775.2120826404315\n",
      "Epoch 2, Loss: 767.4655979144306\n",
      "Epoch 3, Loss: 769.4723883680642\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for (data, _), (aug_data, _) in zip(loader, augmented_loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        z_i = model_2(data)\n",
    "        z_j = model_2(aug_data)\n",
    "        for anchor_index in range(data.size(0)):\n",
    "            z_anchor = z_i[anchor_index].unsqueeze(0)\n",
    "            z_positive = z_j[anchor_index].unsqueeze(0)\n",
    "\n",
    "            for negative_index in range(data.size(0)):\n",
    "                if anchor_index != negative_index:\n",
    "                    z_negative = z_i[negative_index].unsqueeze(0)\n",
    "\n",
    "                    negative_loss = contrastive_loss(z_anchor, z_positive, z_negative, margin=1.0)\n",
    "                    loss += negative_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {average_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUlU_MPcOal6",
    "outputId": "7aace893-6516-4dd0-f785-e74d774e44d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 11.62%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "  for (data,target) in loader:\n",
    "    representations = model_2(data)\n",
    "    outputs = classifier(representations)\n",
    "    _, predicted = torch.max(outputs.data,1)\n",
    "\n",
    "    total+= target.size(0)\n",
    "    correct += (predicted == target).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkDgv4ypTyZN"
   },
   "source": [
    "###Model in 5.1 performed the best, but model 5.2 and 5.2 had weak performance, yet model 5.3 has the better out of the two."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
